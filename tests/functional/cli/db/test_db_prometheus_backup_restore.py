import logging
import math
import os

import pytest
from datetime import datetime, timedelta

from sarc.client import get_jobs
from sarc.client.job import (
    JobStatistics,
    Statistics,
    SlurmJob,
    SlurmState,
    SlurmResources,
)
from sarc.config import config, MTL
from sarc.jobs.node_gpu_mapping import _node_gpu_mapping_collection
from sarc.jobs.series import (
    _get_job_time_series_data_cache_key,
    JOB_STATISTICS_METRIC_NAMES,
)
from enum import StrEnum, auto
import itertools


class GpuCase(StrEnum):
    # Enumeration to test GPU cases.
    NONE = auto()  # No GPU type in job
    FROM_SACCT = auto()  # GPU was parsed from sacct, neither from nodes nor Prometheus
    FROM_NODES = auto()  # GPU can be inferred from nodes
    IN_RAW_CACHE = auto()  # GPU cannot be inferred and is in prometheus raw cache
    IN_DB_ONLY = auto()  # GPU cannot be inferred and is only in DB


class StatsCase(StrEnum):
    """Enumeration to test stored_statistics cases"""

    NONE = auto()  # no stored_statistics in job
    EMPTY = auto()  # stored_statistics is empty
    IN_RAW_CACHE = auto()  # raw statistics are in prometheus raw cache
    IN_DB_ONLY = auto()  # no raw cache, stored_statistics only available in DB


def _gen_job(job_id: int, gpu_case: GpuCase, stats_case: StatsCase):
    """Generate a job on cluster raisin for given job ID, GPU case and stats case."""
    submit_time = datetime(2025, 1, job_id + 1, tzinfo=MTL)
    start_time = submit_time + timedelta(hours=1)
    end_time = start_time + timedelta(hours=1)
    job = SlurmJob(
        account="account",
        name="name",
        user="user",
        group="group",
        partition="partition",
        nodes=[f"node{job_id}"],
        work_dir="work_dir",
        requested=SlurmResources(),
        allocated=SlurmResources(),
        cluster_name="raisin",
        job_id=job_id,
        submit_time=submit_time,
        start_time=start_time,
        end_time=submit_time,
        elapsed_time=(end_time - start_time).total_seconds(),
        job_state=SlurmState.COMPLETED,
    )

    cfg = config()
    prometheus_raw_cache_folder = cfg.cache / "prometheus"

    if gpu_case == GpuCase.NONE:
        gpu_type = None
    elif gpu_case == GpuCase.FROM_SACCT:
        gpu_type = "sacct_gpu"
    else:
        if gpu_case == GpuCase.FROM_NODES:
            gpu_type = "node_gpu"
        else:
            gpu_type = "prometheus_gpu"
        # Anyway, we make sure there are node->gpu mapping
        _node_gpu_mapping_collection().save_node_gpu_mapping(
            job.cluster_name,
            job.submit_time,
            {node: ["node_gpu"] for node in job.nodes},
        )
        if gpu_case == GpuCase.IN_RAW_CACHE:
            # Create prometheus raw cache for gpu
            cache_key = _get_job_time_series_data_cache_key(
                job=job, metric="slurm_job_utilization_gpu_memory", max_points=1
            )
            assert cache_key is not None
            prometheus_raw_cache_folder.mkdir(parents=True, exist_ok=True)
            cache_path = prometheus_raw_cache_folder / cache_key
            assert not cache_path.exists()
            # We don't need real data, file just has to exist
            with open(cache_path, "w", encoding="utf-8"):
                pass

    if stats_case == StatsCase.NONE:
        stored_statistics = None
    elif stats_case == StatsCase.EMPTY:
        stored_statistics = JobStatistics()
        assert stored_statistics.empty()
    else:
        stored_statistics = JobStatistics(
            gpu_utilization=Statistics(
                mean=math.nan,  # add NaN values to check that they are correctly handled
                std=2.2,
                q05=3.3,
                q25=4.4,
                median=5.5,
                q75=math.nan,
                max=7.7,
                unused=8,
            )
        )
        if stats_case != StatsCase.IN_DB_ONLY:
            assert stats_case == StatsCase.IN_RAW_CACHE
            # Create a prometheus raw cache for stats
            cache_key = _get_job_time_series_data_cache_key(
                job, JOB_STATISTICS_METRIC_NAMES, max_points=10_000
            )
            assert cache_key is not None
            prometheus_raw_cache_folder.mkdir(parents=True, exist_ok=True)
            cache_path = prometheus_raw_cache_folder / cache_key
            assert not cache_path.exists(), (
                job_id,
                gpu_case,
                stats_case,
                cache_path,
            )
            with open(cache_path, "w", encoding="utf-8"):
                pass

    job.allocated.gpu_type = gpu_type
    job.stored_statistics = stored_statistics
    return job


@pytest.fixture
def _backup_db(empty_read_write_db, enabled_cache):
    """
    Fixture to populate empty_read_write_db with jobs generated by _gen_job
    for each combination of GPU case and stats case.

    Expectations:

    JOB_ID  GPU             STATS           GPU_IS_COLLECTED    STATS_IS_COLLECTED  JOB_IS_COLLECTED
    ================================================================================================
    0       none            none            no                  no                  ignored
    1       none            empty           no                  no                  no
    2       none            in_raw_cache    no                  no                  no
    3       none            in_db_only      no                  yes                 yes
    4       from_sacct      none            yes                 no                  yes
    5       from_sacct      empty           yes                 no                  yes
    6       from_sacct      in_raw_cache    yes                 no                  yes
    7       from_sacct      in_db_only      yes                 yes                 yes
    8       from_nodes      none            no                  no                  no
    9       from_nodes      empty           no                  no                  no
    10      from_nodes      in_raw_cache    no                  no                  no
    11      from_nodes      in_db_only      no                  yes                 yes
    12      in_raw_cache    none            no                  no                  no
    13      in_raw_cache    empty           no                  no                  no
    14      in_raw_cache    in_raw_cache    no                  no                  no
    15      in_raw_cache    in_db_only      no                  yes                 yes
    16      in_db_only      none            yes                 no                  yes
    17      in_db_only      empty           yes                 no                  yes
    18      in_db_only      in_raw_cache    yes                 no                  yes
    19      in_db_only      in_db_only      yes                 yes                 yes
    ================================================================================================
    TOTAL                                   8                   5                   11 / 15
    """
    for job_id, (gpu_status, stats_status) in enumerate(
        itertools.product(GpuCase.__members__.values(), StatsCase.__members__.values())
    ):
        job = _gen_job(job_id, gpu_status, stats_status)
        job.save()


def test_db_prometheus_backup(_backup_db, caplog, cli_main, file_regression):
    """Test command `sarc db prometheus backup`"""
    caplog.set_level(logging.INFO)
    cfg = config()
    prometheus_backup_dir = cfg.cache / "prometheus_backup"
    assert not prometheus_backup_dir.exists()
    assert cli_main(["-v", "db", "prometheus", "backup"]) == 0
    assert "Collected Prometheus metrics for 11/19 jobs" in caplog.text
    assert "Collected GPU types: 8" in caplog.text
    assert "Skipped GPU types that can be inferred from job nodes: 4" in caplog.text
    assert "Skipped GPU types already in raw prometheus cache: 4" in caplog.text
    assert "Collected statistics: 5" in caplog.text
    assert "Skipped statistics already in raw prometheus cache: 5" in caplog.text

    backup_dir = cfg.cache / "prometheus_backup"
    assert backup_dir.is_dir()
    (backup_filename,) = os.listdir(backup_dir)
    with open(backup_dir / backup_filename, "r", encoding="utf-8") as f:
        backup_content = f.read()

    file_regression.check(backup_content)


def test_db_prometheus_restore(_backup_db, caplog, cli_main):
    """Test command `sarc db prometheus restore`"""
    caplog.set_level(logging.INFO)

    # Backup first
    assert cli_main(["-v", "db", "prometheus", "backup"]) == 0
    backup_dir = config().cache / "prometheus_backup"
    (backup_filename,) = os.listdir(backup_dir)
    backup_filepath = backup_dir / backup_filename
    assert backup_filepath.is_file()

    # Then modify and save some jobs
    nb_modified = 0
    for job in get_jobs():
        to_save = False
        if job.job_id == 3:
            job.stored_statistics = None  # Should be updated even without --force
            to_save = True
        elif job.job_id == 11:
            job.stored_statistics.gpu_utilization.mean = 1
            to_save = True
        elif job.job_id == 16:
            job.allocated.gpu_type = None  # Should be updated even without --force
            to_save = True
        elif job.job_id == 17:
            job.allocated.gpu_type = "another_gpu_type"
            to_save = True
        elif job.job_id == 19:
            job.stored_statistics.gpu_utilization.std = -1.0
            job.allocated.gpu_type = "again_another_gpu_type"
            to_save = True
        if to_save:
            job.save()
            nb_modified += 1

    assert nb_modified == 5

    # Now test restore without --force
    # 2/5 jobs should be updated
    caplog.clear()
    assert (
        cli_main(["-v", "db", "prometheus", "restore", "-i", str(backup_filepath)]) == 0
    )
    assert (
        "No --force. Only null GPU type or stored_statistics in DB would be updated."
        in caplog.text
    )
    assert "Jobs found: 11 / 11" in caplog.text
    assert "Jobs: to update: 5, updated: 2" in caplog.text
    assert "GPU types: to update: 3, updated: 1" in caplog.text
    assert "Prometheus stats: to update: 3, updated: 1" in caplog.text

    # Without --force, no more jobs should be updated
    for _ in range(3):
        caplog.clear()
        assert (
            cli_main(["-v", "db", "prometheus", "restore", "-i", str(backup_filepath)])
            == 0
        )
        assert (
            "No --force. Only null GPU type or stored_statistics in DB would be updated."
            in caplog.text
        )
        assert "Jobs found: 11 / 11" in caplog.text
        assert "Jobs: to update: 3, updated: 0" in caplog.text
        assert "GPU types: to update: 2, updated: 0" in caplog.text
        assert "Prometheus stats: to update: 2, updated: 0" in caplog.text

    # Now restore with --force
    # All 3 remaining jobs should be updated
    caplog.clear()
    assert (
        cli_main(
            ["-v", "db", "prometheus", "restore", "--force", "-i", str(backup_filepath)]
        )
        == 0
    )
    assert (
        "No --force. Only null GPU type or stored_statistics in DB would be updated."
        not in caplog.text
    )
    assert "Jobs found: 11 / 11" in caplog.text
    assert "Jobs: to update: 3, updated: 3" in caplog.text
    assert "GPU types: to update: 2, updated: 2" in caplog.text
    assert "Prometheus stats: to update: 2, updated: 2" in caplog.text

    # No more updates should occur
    for _ in range(3):
        caplog.clear()
        assert (
            cli_main(
                [
                    "-v",
                    "db",
                    "prometheus",
                    "restore",
                    "--force",
                    "-i",
                    str(backup_filepath),
                ]
            )
            == 0
        )
        assert (
            "No --force. Only null GPU type or stored_statistics in DB would be updated."
            not in caplog.text
        )
        assert "Jobs found: 11 / 11" in caplog.text
        assert "Jobs: to update: 0, updated: 0" in caplog.text
        assert "GPU types: to update: 0, updated: 0" in caplog.text
        assert "Prometheus stats: to update: 0, updated: 0" in caplog.text
